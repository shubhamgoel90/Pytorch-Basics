{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_1.3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamgoel90/Pytorch-Basics/blob/master/rnn_1_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRWWZMtYNMEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "from torch import nn \n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O1GqT8qpeWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "    loss = loss_func(model(xb), yb)\n",
        "\n",
        "    if opt is not None:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "\n",
        "    return loss.item(), len(xb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCWKO88fP-yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for xb, yb in train_dl:\n",
        "            loss_batch(model, loss_func, xb, yb, opt)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            losses, nums = zip(\n",
        "                *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "            )\n",
        "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "\n",
        "        print(epoch, val_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37rTqaZ3QWKz",
        "colab_type": "code",
        "outputId": "aa00f919-8f65-4fda-f942-f1e1e3f598ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XXDsAX9RDrg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=open('/content/drive/My Drive/shakespeare.txt').read()[7800:].lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da3iLTTZBmUK",
        "colab_type": "code",
        "outputId": "a9cda2e4-a472-4429-ac58-fcaeee0d575a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print (text[:100])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creatures we desire increase,\n",
            "  that thereby beauty's rose might never die,\n",
            "  but as the riper shoul\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqQ-O-RERVNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "itos = list(set(text))\n",
        "itos.insert(0,'unk')\n",
        "itos.insert(0,'pad')\n",
        "stoi = { x:i for i,x in enumerate(itos)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKf44UbvBvZK",
        "colab_type": "code",
        "outputId": "818b0b76-7740-49c2-d5dc-8f0500bdb70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "itos[48]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXkPVrZJTJBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [stoi[i] for i in text][:25000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySTli5JECFXi",
        "colab_type": "code",
        "outputId": "ad79b611-004f-4236-a1b6-fca42145c73a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data[:5],[ itos[i] for i in data[:5]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2, 38, 23, 48, 32], ['c', 'r', 'e', 'a', 't'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep5f1DIpS7P8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cs = 10\n",
        "xs=np.array([data[ix:cs+ix] for ix in range(0,len(data)-cs)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdTQciunar42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = xs[:20000,:9]\n",
        "y_train = xs[:20000,9]\n",
        "\n",
        "x_val = xs[20000:,:9]\n",
        "y_val = xs[20000:,9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TE_btHE3XXCH",
        "colab_type": "code",
        "outputId": "790d5f67-3fb2-44f2-dbc1-6e9da11a6f69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(x_train),len(y_train),len(x_val),len(y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 20000, 4990, 4990)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhkRAmiQCXxo",
        "colab_type": "code",
        "outputId": "5a679f7e-0541-43e3-9075-e9023c0e0d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train[0],y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 2, 38, 23, 48, 32, 54, 38, 23, 26]), 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjkIBCA_Y1_z",
        "colab_type": "code",
        "outputId": "8fb50c31-e3ff-438f-8d6f-654ec2fabb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "''.join([itos[i] for i in x_train[0]]),itos[y_train[0]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('creatures', ' ')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKbO6SYBioVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_val, y_val = map(\n",
        "    torch.tensor, (x_train, y_train, x_val, y_val)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcivdqxxcwsW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "bs = 512\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=bs)\n",
        "\n",
        "\n",
        "val_ds = TensorDataset(x_val, y_val)\n",
        "val_dl = DataLoader(val_ds, batch_size=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNPBphVlD7YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bs,seq_len --> bs,seq_len,emb --> bs,seq_len,hid --> LSTM --> bs,seq_len,vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxMVkE_bDhCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class lstm_model(nn.Module):\n",
        "  def __init__(self,vs,emb,hid):\n",
        "    super().__init__()\n",
        "    self.vs,self.emb,self.hid=vs, emb,hid\n",
        "    self.emb = nn.Embedding(vs,emb)\n",
        "    self.layer = nn.Linear(emb,hid)\n",
        "    self.rnn = nn.RNN(hid,hid)\n",
        "    self.out = nn.Linear(hid,vs)\n",
        "  def forward(self,xb):\n",
        "    e  = self.emb(xb)\n",
        "    o = F.tanh(self.layer(xb))\n",
        "    bs = len(xb)\n",
        "    hid = torch.zeros(bs,self.hid)\n",
        "    out,hid  = self.rnn(o,hid)\n",
        "    print (out.shape)\n",
        "    return F.log_softmax(self.out(out[:,-1]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UuNzUIyL4HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mse(xb,xp):\n",
        "  return ((xb-xp)**2).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK5iw3T0E8Hb",
        "colab_type": "code",
        "outputId": "9e27f7d4-2eff-4a83-e3c8-f6d88795b928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "m = lstm_model(len(itos),100,128);m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "lstm_model(\n",
              "  (emb): Embedding(66, 100)\n",
              "  (layer): Linear(in_features=100, out_features=128, bias=True)\n",
              "  (rnn): RNN(128, 128)\n",
              "  (out): Linear(in_features=128, out_features=66, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "relxuoPPi4dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class model(nn.Module):\n",
        "  def __init__(self,vs,emb,hid):\n",
        "    super().__init__()\n",
        "    self.vs,self.emb,self.hid = vs,emb,hid\n",
        "    self.emb =  nn.Embedding(vs,emb)\n",
        "    self.l1= nn.Linear(emb,hid)\n",
        "    self.rnn = nn.RNN(hid,hid,batch_first=True)\n",
        "    self.out = nn.Linear(hid,vs)\n",
        "  \n",
        "  def forward(self,xb):\n",
        "    bs = xb.shape[0]\n",
        "    hid = torch.zeros((bs,self.hid),requires_grad=True)\n",
        "    inp = self.emb(xb)\n",
        "    inp = F.sigmoid(self.l1(inp))\n",
        "    out,hid = self.rnn(inp) \n",
        "    print (out.shape)\n",
        "    return F.log_softmax(self.out(out[:,-1]),dim=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys2OT-5_na8L",
        "colab_type": "code",
        "outputId": "2bfd2fd5-4a53-4d33-caf6-b4a906724931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "m = model(len(itos),100,128);m"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model(\n",
              "  (emb): Embedding(66, 100)\n",
              "  (l1): Linear(in_features=100, out_features=128, bias=True)\n",
              "  (rnn): RNN(128, 128, batch_first=True)\n",
              "  (out): Linear(in_features=128, out_features=66, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf8AYEYCpSZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = optim.Adam(m.parameters(),lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRkQK1DsIHeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEy_NlQen--1",
        "colab_type": "code",
        "outputId": "ac9287c1-b33c-41ca-e7cf-71e5e233ce5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "fit(20,m,F.cross_entropy,opt,train_dl,val_dl)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 2.855373767191518\n",
            "1 2.645996330066291\n",
            "2 2.4215269948772056\n",
            "3 2.2787323020025343\n",
            "4 2.1825726437425326\n",
            "5 2.1174642035383022\n",
            "6 2.0704538488674737\n",
            "7 2.0319062318973886\n",
            "8 1.9997156408841241\n",
            "9 1.9718753654636696\n",
            "10 1.9484026430126182\n",
            "11 1.9265503534573114\n",
            "12 1.9073958137947955\n",
            "13 1.8907849270260644\n",
            "14 1.8765236440306914\n",
            "15 1.8643039958032672\n",
            "16 1.8529305908149611\n",
            "17 1.8415468961776855\n",
            "18 1.8298121384484973\n",
            "19 1.8194092883853492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKyCAEv7IIoG",
        "colab_type": "code",
        "outputId": "365eb10f-8f79-4ff5-a1c7-e2a51f4c8648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "(m(torch.tensor(data[:10])[None]).exp().detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.31160177e-05, 2.84023135e-05, 1.53070260e-02, 7.00378418e-02,\n",
              "        9.52766204e-05, 1.99349288e-05, 6.89589158e-02, 8.44296446e-05,\n",
              "        4.39821852e-05, 2.90087737e-05, 1.66967802e-05, 2.00599106e-03,\n",
              "        3.94045562e-02, 3.92964408e-02, 4.83288983e-04, 2.82881047e-05,\n",
              "        1.15406001e-02, 4.67356443e-02, 2.44178209e-05, 2.17226516e-05,\n",
              "        5.33140302e-02, 2.31478605e-02, 2.58185640e-02, 1.47205172e-02,\n",
              "        4.31337976e-05, 3.85300518e-05, 5.42619862e-02, 1.66297032e-05,\n",
              "        4.10719404e-05, 4.92974686e-05, 2.06538243e-05, 2.76556420e-05,\n",
              "        1.63160011e-01, 2.22341763e-03, 4.66442252e-05, 1.99374954e-05,\n",
              "        6.80993107e-05, 1.92432217e-05, 1.69671513e-02, 8.39310233e-05,\n",
              "        1.50210772e-05, 2.14451939e-04, 1.70759755e-04, 2.28000172e-05,\n",
              "        6.86738268e-02, 2.77536809e-02, 6.53991592e-05, 6.77206144e-02,\n",
              "        9.22604576e-02, 8.80084190e-06, 1.42693143e-05, 2.83460031e-05,\n",
              "        2.71932259e-02, 2.26023680e-04, 4.21692384e-03, 1.08168615e-05,\n",
              "        9.27568399e-05, 2.20918118e-05, 8.58757994e-06, 1.20203174e-03,\n",
              "        5.65590011e-03, 1.23817745e-05, 8.60007538e-04, 5.34155630e-02,\n",
              "        1.78754784e-03, 8.37597472e-05]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPRX-tY8IIZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSMEl0dgp_qe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate(sent):\n",
        "  inp = torch.tensor([stoi[i] for i in sent])\n",
        "  p = m(inp[None]).exp().detach().numpy()[0]\n",
        "  #print (sum(p))\n",
        "  #return itos[np.argmax(p)]\n",
        "  return (np.random.choice(itos,p=p))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjgHcsM9rZeq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_n(sent,n=10):\n",
        "  for i in range(n):\n",
        "    sent+=generate(sent[-9:])\n",
        "  return sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoYA_W2iqf6n",
        "colab_type": "code",
        "outputId": "9d8a25d3-0fea-4e3f-a209-879b6e783a4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "print (gen_n('this is',n=1000))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "this is that my ig tell ginougrith thith codes my pake for my entimy for actees my het linde's nen ightil's thount of the sare, hourtron: and thee mave delte,\n",
            "  anp porp theoh llaly sech stores from ay sombest nighte\n",
            "  thy self babe digh with.\n",
            "  shast ow owt ig an ryed pustom live wior thoo erssang theautet\n",
            "  sorments your thou ard blions howning has it, eyed seet, simthen beas brow ceirtlm's then then sone gorpsteds eyat youngr in with the way thill when lovangine,\n",
            "  a gite pithe,\n",
            "  wyout'st by gren,\n",
            "  the beret of geouty's shy a coongterend,\n",
            "  i dath neade ightss shate,\n",
            "  try meake anl'kid minger ftire, shoued youn youn the shounth cyet whing un thif mi dades is dath matast nich wall,\n",
            "  what thine to pited,\n",
            "    apken wirl,\n",
            "  lovings a wite dith sim and the maken bespeds dreps.\n",
            "  to their paavt\n",
            "\n",
            "  for five,\n",
            "  and oy partt dwate thouters me tome o'enn menuidst troust sy livt at;\n",
            "  fo fot make old mave br doke propity she heo ant\n",
            "  pur hach elight on thanmen minge teet het my wiesle on thy mpa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ4EnnChK95R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "itos = ['the','is','\"']"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}